---
layout: post
title: 'Python爬虫-爬取《星际穿越》短评并提取关键词'
subtitle: '星际穿越'
date: 2020-04-07
categories: 技术
tags: Python 技术 爬虫
cover: 'https://lz.sinaimg.cn/orj1080/ebeef3aaly3gdkzbkaji9j21bz0vzgyf.jpg'
---

<p>https://cdn.jsdelivr.net/gh/JMbaozi/Blogimg/Music/Hans%20Zimmer%20-%20Cornfield%20Chase.mp3</p>
这次选择了我最喜欢的电影[《星际穿越》](https://movie.douban.com/subject/1889243/comments?status=P)的短评，共爬取了500条评论，并且用jieba分词提取了100个关键词。[程序文件点我查看](https://github.com/JMbaozi/absorb/tree/master/program/movieAnalyse)

100个关键词中有感情色彩的 “情感”，”亲情“，”人性“，”煽情“权重值较高，也很好的反映了《星际迷航》剧情的走向和发展。”震撼“，”五星“，”神作“，”烧脑“等页说明了这部电影的深度和精彩。

#### 剧情简介

近未来的地球黄沙遍野，小麦、秋葵等基础农作物相继因枯萎病灭绝，人类不再像从前那样仰望星空，放纵想象力和灵感的迸发，而是每日在沙尘暴的肆虐下倒数着所剩不多的光景。在家务农的前NASA宇航员库珀（马修·麦康纳 Matthew McConaughey 饰）接连在女儿墨菲（麦肯吉·弗依 Mackenzie Foy 饰）的书房发现奇怪的重力场现象，随即得知在某个未知区域内前NASA成员仍秘密进行一个拯救人类的计划。多年以前土星附近出现神秘虫洞，NASA借机将数名宇航员派遣到遥远的星系寻找适合居住的星球。在布兰德教授（迈克尔·凯恩 Michael Caine 饰）的劝说下，库珀忍痛告别了女儿，和其他三名专家教授女儿艾米莉亚·布兰德（安妮·海瑟薇 Anne Hathaway 饰）、罗米利（大卫·吉雅西 David Gyasi 饰）、多伊尔（韦斯·本特利 Wes Bentley 饰）搭乘宇宙飞船前往目前已知的最有希望的三颗星球考察。
　　他们穿越遥远的星系银河，感受了一小时七年光阴的沧海桑田，窥见了未知星球和黑洞的壮伟与神秘。在浩瀚宇宙的绝望而孤独角落，总有一份超越了时空的笃定情怀将他们紧紧相连……
![](https://cdn.jsdelivr.net/gh/JMbaozi/Blogimg/Pictures/星际穿越.jpg)

#### 流程

* 爬取短评
* 保存评论
* 用jieba模块提取关键词
* 保存关键词及其权重值

游客访问豆瓣只能爬取11页评论，所以要先登入自己的账号，找到对应的Cookie作为标头，这样就可以爬取所有的短评了。(我把我的Cookie删掉了，你可以用你自己的Cookie来设置。)

1.爬取短评
```python
def getComments(id,pageNum):
    movieComments = ""
    for i in range(pageNum):
        start = i*20
        url = "https://movie.douban.com/subject/"+str(id)+"/comments?start="+str(start)+"&limit=20&sort=new_score&status=P"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.92 Safari/537.36 Edg/81.0.416.45',
            'Cookie':''
        }
        print("正在爬取第%s页评论" % (i+1))
        r = requests.get(url,headers=headers)
        soup = BeautifulSoup(r.text,'lxml')
        commentsList = soup.find_all('span',class_ ='short')
        for comments in commentsList:
            movieComments += comments.text
            movieComments += '\n'
    return movieComments
```

2.保存评论
```python
def saveComments(Comments):
    try:
        fileName = 'movieComments.txt'
        with open(fileName,'w',encoding='utf-8') as f:
            f.write(str(Comments))
        print('保存成功！')
    except:
        print('保存失败！')
```

3.用jieba模块提取关键词
```python
keyWord = []
Weight = []
def getData():
    with open('movieComments.txt',encoding = 'utf-8') as f:
        data = f.read()
    for keyword, weight in extract_tags(data, topK=100, withWeight=True):
        keyWord.append(keyword)
        Weight.append(weight)
```

4.保存关键词及其权重值
```python
def saveData(keyWord,Weight):
    with open('TF-IDFanalyse.txt','w') as f:
        for i in range(len(keyWord)):
            f.write(str(i+1)+'.'+str(keyWord[i])+' '+str(Weight[i]))
            f.write('\n')
```

#### 完整代码

```python
"""
Author:JMbaozi
Movie:星际穿越
MovieID:1889243
Total:500条
"""

import requests
import lxml
from bs4 import BeautifulSoup

def getComments(id,pageNum):
    movieComments = ""
    for i in range(pageNum):
        start = i*20
        url = "https://movie.douban.com/subject/"+str(id)+"/comments?start="+str(start)+"&limit=20&sort=new_score&status=P"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.92 Safari/537.36 Edg/81.0.416.45',
            'Cookie':''
        }
        print("正在爬取第%s页评论" % (i+1))
        r = requests.get(url,headers=headers)
        soup = BeautifulSoup(r.text,'lxml')
        commentsList = soup.find_all('span',class_ ='short')
        for comments in commentsList:
            movieComments += comments.text
            movieComments += '\n'
    return movieComments

def saveComments(Comments):
    try:
        fileName = 'movieComments.txt'
        with open(fileName,'w',encoding='utf-8') as f:
            f.write(str(Comments))
        print('保存成功！')
    except:
        print('保存失败！')

if __name__ == '__main__':
    id = '1889243'
    pageNum = 25
    Comments = getComments(id,pageNum)
    saveComments(Comments)

```

```python
from jieba.analyse import *

keyWord = []
Weight = []
def getData():
    with open('movieComments.txt',encoding = 'utf-8') as f:
        data = f.read()
    for keyword, weight in extract_tags(data, topK=100, withWeight=True):
        keyWord.append(keyword)
        Weight.append(weight)

def saveData(keyWord,Weight):
    with open('TF-IDFanalyse.txt','w') as f:
        for i in range(len(keyWord)):
            f.write(str(i+1)+'.'+str(keyWord[i])+' '+str(Weight[i]))
            f.write('\n')

if __name__ == '__main__':
    getData()
    saveData(keyWord,Weight)
    print('保存成功！')
```

![](https://lz.sinaimg.cn/orj1080/ebeef3aaly3gdkzbjwn2uj21kw11xtpn.jpg)