---
layout: post
title: 'Python爬虫-爬取豆瓣电影TOP250'
subtitle: '豆瓣电影'
date: 2020-02-28
categories: 技术
tags: Python 技术
music-id: 1375469494
---

> 之前挖的动态网页爬虫坑一直没有填，现在也不想填。。。

> 碰巧看到了这篇[教程](https://cloud.tencent.com/developer/article/1404219)，就学习了一下。

> 这次就不加详细注释了，只加部分说明性的注释。有不懂的地方可以联系我。

我将获得的结果写入了txt文件中
* [代码下载](https://github.com/JMbaozi/absorb/blob/master/Blog/program/%E8%B1%86%E7%93%A3%E7%94%B5%E5%BD%B1TOP250.py)
* [txt下载](https://github.com/JMbaozi/absorb/blob/master/Blog/file/%E8%B1%86%E7%93%A3%E7%94%B5%E5%BD%B1TOP250.txt)

> 这只实现了获取电影名称的功能，后续再写评分、评论什么的（又挖坑。。。）

我在第一个博客中写了爬取静态网页图片的代码，其中用BeautifulSoup对总页数进行了解析，共44页，其实这一步是多余的，因为可以很清晰的看到一共就44页。。。
所以这次我直接循环10次来爬这10页的电影名。

#### 完整代码
```python
"""
https://movie.douban.com/top250?start=0&filter=
"""

import re,requests,lxml
from bs4 import BeautifulSoup
def get_movies():
    movies_list = []
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.26 Safari/537.36 Edg/81.0.416.16',
        'Host':'movie.douban.com'
    }
    for i in range(0,10):
        link = 'https://movie.douban.com/top250?start=' + str(i*25) + '&filter='    #从网址中可以很明显的发现，'start='的结果为i*25
        r = requests.get(link,headers=headers,timeout = 10)     #获得当前页的html内容
        soup = BeautifulSoup(r.text,'lxml')     #对当前页的内容进行解析
        div_list = soup.find_all('div',class_='hd')
        for each in div_list:
            #movie = re.findall("<span class ='title'>(.*?)</span>",each.text).strip()
            movie = each.a.span.text.strip()    #获取电影名，并清除多余的空格
            movies_list.append(movie)
    return movies_list

movies = get_movies()
print(movies)

#将movies列表写入 豆瓣TOP250.txt
number = 1      #排名
file = open('E:\\blog\\program\\豆瓣TOP250.txt','w')
for each in movies:
    file.write(str(number)+'：'+each)
    file.write('\n')
    number+=1
file.close()
print('写入完成！')
    
```
![1](https://lz.sinaimg.cn/orj1080/ebeef3aaly3gcci3blchlj20rq0jlacz.jpg)
